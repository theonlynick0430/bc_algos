{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bc_algos.models.obs_core import EncoderCore, VisualCore\n",
    "from bc_algos.models.obs_nets import ObservationEncoder, ObservationGroupEncoder\n",
    "import bc_algos.utils.obs_utils as ObsUtils\n",
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "state_shape = [3,]\n",
    "img_shape = [3, 224, 162,]\n",
    "output_shape = [4, 4,]\n",
    "hidden_dim=[64, 18, 64,]\n",
    "x_low_dim = 2*torch.rand(batch_size, *state_shape)-1\n",
    "x_rgb = 2*torch.rand(batch_size, *img_shape)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test encoder core with no specified output shape\n",
    "enc_core = EncoderCore(input_shape=state_shape)\n",
    "y_low_dim = enc_core(x_low_dim)\n",
    "assert list(y_low_dim.shape) == [batch_size,]+state_shape\n",
    "assert list(y_low_dim.shape) == [batch_size,]+enc_core.output_shape\n",
    "# test encoder core with specified output shape\n",
    "enc_core = EncoderCore(input_shape=state_shape, output_shape=output_shape, hidden_dim=hidden_dim)\n",
    "y_low_dim = enc_core(x_low_dim)\n",
    "assert list(y_low_dim.shape) == [batch_size,]+output_shape\n",
    "assert list(y_low_dim.shape) == [batch_size,]+enc_core.output_shape\n",
    "# test visual core with no specified output shape\n",
    "visual_core = VisualCore(input_shape=img_shape)\n",
    "y_rgb = visual_core(x_rgb)\n",
    "assert list(y_rgb.shape) == [batch_size, 768,]\n",
    "assert list(y_rgb.shape) == [batch_size,]+visual_core.output_shape\n",
    "# test visual core with specified output shape\n",
    "visual_core = VisualCore(input_shape=img_shape, output_shape=output_shape, hidden_dim=hidden_dim)\n",
    "y_rgb = visual_core(x_rgb)\n",
    "assert list(y_rgb.shape) == [batch_size,]+output_shape\n",
    "assert list(y_rgb.shape) == [batch_size,]+visual_core.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation/Group Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObsUtils.register_encoder_core(EncoderCore, ObsUtils.Modality.LOW_DIM)\n",
    "ObsUtils.register_encoder_core(VisualCore, ObsUtils.Modality.RGB)\n",
    "\n",
    "obs_enc = ObservationEncoder()\n",
    "obs_enc.register_obs_key(\n",
    "    obs_key=\"robot0_eef_pos\",\n",
    "    modality=ObsUtils.Modality.LOW_DIM,\n",
    "    input_shape=state_shape,\n",
    ")\n",
    "\n",
    "goal_enc = ObservationEncoder()\n",
    "goal_enc.register_obs_key(\n",
    "    obs_key=\"agentview_image\",\n",
    "    modality=ObsUtils.Modality.RGB,\n",
    "    input_shape=img_shape,\n",
    ")\n",
    "\n",
    "group_enc = ObservationGroupEncoder()\n",
    "group_enc.register_obs_group(obs_group=\"obs\", obs_enc=obs_enc)\n",
    "group_enc.register_obs_group(obs_group=\"goal\", obs_enc=goal_enc)\n",
    "\n",
    "inputs = OrderedDict({\"obs\": {\"robot0_eef_pos\": x_low_dim}, \"goal\": {\"agentview_image\": x_rgb}})\n",
    "y = group_enc(inputs)\n",
    "assert list(y.shape) == [batch_size,]+group_enc.output_shape\n",
    "\n",
    "ObsUtils.unregister_encoder_core(ObsUtils.Modality.LOW_DIM)\n",
    "ObsUtils.unregister_encoder_core(ObsUtils.Modality.RGB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
