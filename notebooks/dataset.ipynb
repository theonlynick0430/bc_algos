{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilsridhar/opt/anaconda3/envs/mental-models/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bc_algos.dataset.robomimic import RobomimicDataset\n",
    "from bc_algos.utils.constants import Modality, GoalMode\n",
    "import bc_algos.utils.obs_utils as ObsUtils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def display(img):\n",
    "    if not isinstance(img, list):\n",
    "        img = [img]\n",
    "    _, axs = plt.subplots(1, len(img))\n",
    "    for i in range(len(img)):\n",
    "        axs[i].imshow(img[i].astype(int))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bc_algos.utils.misc import load_gzip_pickle\n",
    "test = load_gzip_pickle(\"../datasets/dataset_v4/run_0.pkl.gzip\")\n",
    "print(test.keys())\n",
    "print(test[\"state\"].keys())\n",
    "print(test[\"obs\"].keys())\n",
    "print(test[\"policy\"].keys())\n",
    "print(test[\"metadata\"].keys())\n",
    "print(test[\"metadata\"][\"num_steps\"])\n",
    "print(test[\"obs\"][\"images\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization Utils Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "state_shape = [2, 2,]\n",
    "\n",
    "traj0_dict = {\n",
    "    \"state\": 2*np.random.randn(T, *state_shape)-1,\n",
    "}\n",
    "traj1_dict = {\n",
    "    \"state\": 2*np.random.randn(T, *state_shape)-1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj0_stats = ObsUtils.compute_traj_stats(traj0_dict)\n",
    "traj1_stats = ObsUtils.compute_traj_stats(traj1_dict)\n",
    "merged_stats = ObsUtils.aggregate_traj_stats(traj0_stats, traj1_stats)\n",
    "traj0_norm_stats = ObsUtils.compute_normalization_stats(traj0_stats)\n",
    "merged_norm_stats = ObsUtils.compute_normalization_stats(merged_stats)\n",
    "\n",
    "traj0_state = traj0_dict[\"state\"]\n",
    "assert np.allclose(traj0_norm_stats[\"state\"][\"mean\"], traj0_state.mean(axis=0))\n",
    "assert np.allclose(traj0_norm_stats[\"state\"][\"stdv\"], np.std(traj0_state, axis=0))\n",
    "merged_state = np.concatenate((traj0_dict[\"state\"], traj1_dict[\"state\"]), axis=0)\n",
    "assert np.allclose(merged_norm_stats[\"state\"][\"mean\"], merged_state.mean(axis=0))\n",
    "assert np.allclose(merged_norm_stats[\"state\"][\"stdv\"], np.std(merged_state, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_key_to_modality = {\"robot0_eef_pos\": Modality.LOW_DIM, \"robot0_eef_quat\": Modality.LOW_DIM, \"agentview_image\": Modality.RGB}\n",
    "obs_group_to_key = {\"obs\": [\"robot0_eef_pos\", \"robot0_eef_quat\", \"agentview_image\"], \n",
    "                     \"goal\": [\"agentview_image\"]}\n",
    "dataset_keys = [\"actions\"]\n",
    "dataset_path = \"../datasets/test/square_ph.hdf5\"\n",
    "demos = [\"demo_0\"]\n",
    "frame_stack = 1\n",
    "seq_length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "caching index: 100%|██████████| 127/127 [00:00<00:00, 33750.02demo/s]\n",
      "loading dataset into memory: 100%|██████████| 1/1 [00:00<00:00, 106.55demo/s]\n",
      "computing normalization stats: 100%|██████████| 1/1 [00:00<00:00, 2226.28demo/s]\n",
      "normalizing data: 100%|██████████| 1/1 [00:00<00:00, 7810.62demo/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = RobomimicDataset(\n",
    "    path=dataset_path,\n",
    "    obs_key_to_modality=obs_key_to_modality,\n",
    "    obs_group_to_key=obs_group_to_key, \n",
    "    dataset_keys=dataset_keys, \n",
    "    frame_stack=frame_stack,\n",
    "    seq_length=seq_length,\n",
    "    goal_mode=None, \n",
    "    num_subgoal=None,\n",
    "    pad_frame_stack=True, \n",
    "    pad_seq_length=True,\n",
    "    get_pad_mask=True,\n",
    "    demos=demos,\n",
    "    preprocess=False,\n",
    "    normalize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(frame_stack):\n",
    "    pad_mask = dataset[i][\"pad_mask\"]\n",
    "    gt_mask = np.array([0] * (frame_stack-i) + [1] * (seq_length+i))\n",
    "    assert np.all(np.equal(pad_mask, gt_mask))\n",
    "for i in range(1, seq_length):\n",
    "    pad_mask = dataset[-i][\"pad_mask\"]\n",
    "    gt_mask = np.array([1] * (frame_stack+i) + [0] * (seq_length-i))\n",
    "    assert np.all(np.equal(pad_mask, gt_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Fetching Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(frame_stack, len(dataset)-(seq_length-1)):\n",
    "    frame = dataset[i]\n",
    "    obs = frame[\"obs\"][\"agentview_image\"]\n",
    "    T = obs.shape[0]\n",
    "    for j in range(T-1):\n",
    "        assert np.any(np.not_equal(obs[j], obs[j+1]))\n",
    "\n",
    "# for i in range(frame_stack, len(dataset)-1):\n",
    "#     frame_a = dataset[i]\n",
    "#     frame_b = dataset[i+1]\n",
    "#     obs_a = frame_a[\"obs\"][\"agentview_image\"]\n",
    "#     obs_b = frame_b[\"obs\"][\"agentview_image\"]\n",
    "#     T = obs_a.shape[0]\n",
    "#     for j in range(1, T):\n",
    "#         assert np.any(np.not_equal(obs_a[j-1], obs_a[j]))\n",
    "    \n",
    "# framefs = dataset[frame_stack][\"obs\"][\"agentview_image\"]\n",
    "# assert np.any(np.not_equal(frames0[0], frames0[1]))\n",
    "# assert np.any(np.not_equal(frames0[1], frames0[2]))\n",
    "# frames1 = dataset[1][\"obs\"][\"agentview_image\"]\n",
    "# assert np.all(np.equal(frames0[1], frames1[0]))\n",
    "# assert np.all(np.equal(frames0[2], frames1[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Goal Condition on Last Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.goal_mode = GoalMode.LAST\n",
    "dataset.cache_index()\n",
    "itemF = dataset[0]\n",
    "itemL = dataset[-1]\n",
    "T_obs = itemF[\"obs\"][\"agentview_image\"].shape[0]\n",
    "T_goal = itemF[\"goal\"][\"agentview_image\"].shape[0]\n",
    "assert T_obs == T_goal\n",
    "goalF = itemF[\"goal\"][\"agentview_image\"][0]\n",
    "goalL = itemL[\"goal\"][\"agentview_image\"][0]\n",
    "assert np.all(np.equal(goalF, goalL))\n",
    "display([goalF, goalL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dense Subgoals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.goal_mode = GoalMode.\n",
    "dataset.cache_index()\n",
    "goal0 = dataset[0][\"goal\"][\"agentview_image\"][0]\n",
    "goal1 = dataset[1][\"goal\"][\"agentview_image\"][0]\n",
    "assert np.any(np.not_equal(goal0, goal1))\n",
    "display([goal0, goal1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Sparse Subgoals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.goal_mode = \"subgoal\"\n",
    "dataset.num_subgoal = 10\n",
    "dataset.cache_index()\n",
    "goal0 = dataset[0][\"goal\"][\"agentview_image\"][0]\n",
    "goal1 = dataset[1][\"goal\"][\"agentview_image\"][0]\n",
    "goalL = dataset[-1][\"goal\"][\"agentview_image\"][0]\n",
    "assert np.all(np.equal(goal0, goal1))\n",
    "assert np.any(np.not_equal(goal1, goalL))\n",
    "display([goal0, goal1, goalL])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
